{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tosshee/ML/blob/main/3_Env_Oracular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIDAv72o0do5"
      },
      "outputs": [],
      "source": [
        "# Requirements\n",
        "'''\n",
        "numpy>=1.23\n",
        "google-cloud-pubsub\n",
        "google-auth\n",
        "yahoo_fin>=0.8\n",
        "scikit-learn\n",
        "tensorflow>=2.0\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yahoo_fin\n",
        "!pip install google-cloud-pubsub\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "Psss4WnL0gkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart after installation\n",
        "# (needs for Pub/Sub libraries)\n",
        "exit()"
      ],
      "metadata": {
        "id": "Jj46Vdnj0tJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time as tm\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "import requests as req\n",
        "import json as js\n",
        "\n",
        "# Data preparation\n",
        "from yahoo_fin import stock_info as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from collections import deque\n",
        "\n",
        "# AI\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "# Pubsub GCP\n",
        "from google.cloud import pubsub_v1\n",
        "from google.oauth2 import service_account\n",
        "from concurrent.futures import TimeoutError\n",
        "\n",
        "# To exclude GPU from work in GCP\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "\n",
        "# SETTINGS\n",
        "ORACULAR_ID = 'Shark oracular'\n",
        "\n",
        "TELEGRAM_URL = 'https://api.telegram.org'\n",
        "TELEGRAM_BOT_ID = 'bot0000000000:AAA_gNNN00B0xxxDaaaUD00HHH-Y0wAAmhA' # Trading bot\n",
        "TELEGRAM_CHAT_ID = '-1002003005001' # Trading bot channel\n",
        "\n",
        "PUBSUB_PROJECT_ID = '[PROJECT ID]'\n",
        "PUBSUB_SCREENER_TOPIC_SUB_ID = 'SharkScreenerTopic-sub'\n",
        "PUBSUB_ORACULAR_TOPIC_SUB_ID = 'SharkOracularTopic-sub'\n",
        "PUBSUB_ORACULAR_TOPIC_ID = 'SharkOracularTopic'\n",
        "PUBSUB_TIMEOUT = 5.0\n",
        "\n",
        "N_STEPS = 7\n",
        "\n",
        "LOOKUP_STEPS = [1, 2, 3]\n",
        "\n",
        "secret = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"[PROJECT ID]\",\n",
        "  \"private_key_id\": \"[PRIVATE KEY ID]\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n[PRIVATE KEY]==\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"[PROJECT_ID]@appspot.gserviceaccount.com\",\n",
        "  \"client_id\": \"[CLIENT_ID]\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/[PROJECT_ID]%40appspot.gserviceaccount.com\"\n",
        "}\n",
        "\n",
        "service_account_info = js.loads(js.dumps(secret))\n",
        "credentials = service_account.Credentials. \\\n",
        "              from_service_account_info(service_account_info)\n",
        "\n",
        "# Send message to Telegram channel\n",
        "def send_message(message):\n",
        "  response = req.post(\n",
        "        f'{TELEGRAM_URL}/{TELEGRAM_BOT_ID}/sendMessage?chat_id={TELEGRAM_CHAT_ID}&parse_mode=Markdown&text={message}')\n",
        "\n",
        "  return response\n",
        "\n",
        "# Load data from Pub/Sub infrastructure\n",
        "def LoadSub(sub_name):\n",
        "  data = []\n",
        "\n",
        "  subscriber = pubsub_v1.SubscriberClient(credentials=credentials)\n",
        "  subscription_path = subscriber.subscription_path(PUBSUB_PROJECT_ID, sub_name)\n",
        "\n",
        "  def callback(message: pubsub_v1.subscriber.message.Message):\n",
        "      data.append(message)\n",
        "\n",
        "  streaming_pull_future = subscriber \\\n",
        "    .subscribe(subscription_path, callback=callback)\n",
        "\n",
        "  with subscriber:\n",
        "      try:\n",
        "          streaming_pull_future.result(timeout=PUBSUB_TIMEOUT)\n",
        "      except TimeoutError:\n",
        "          streaming_pull_future.cancel()\n",
        "          streaming_pull_future.result()\n",
        "\n",
        "  return data\n",
        "\n",
        "# Publish predictions fot the stock\n",
        "def PublishPredictions(stock, day_1, day_2, day_3):\n",
        "  publisher = pubsub_v1.PublisherClient(credentials=credentials)\n",
        "  topic_path = publisher.topic_path(PUBSUB_PROJECT_ID, PUBSUB_ORACULAR_TOPIC_ID)\n",
        "  data_str = f'{stock}'\n",
        "  data = data_str.encode(\"utf-8\")\n",
        "  publisher.publish(topic_path, \\\n",
        "                    data, \\\n",
        "                    stock=stock, \\\n",
        "                    day_1=f'{day_1}', \\\n",
        "                    day_2=f'{day_2}', \\\n",
        "                    day_3=f'{day_3}')\n",
        "\n",
        "# Get stocks for work\n",
        "def GetStocks():\n",
        "  stocks = []\n",
        "\n",
        "  screener = LoadSub(PUBSUB_SCREENER_TOPIC_SUB_ID)\n",
        "  oracular = LoadSub(PUBSUB_ORACULAR_TOPIC_SUB_ID)\n",
        "\n",
        "  oracular_list = [x.attributes['stock'] for x in oracular]\n",
        "  pair_list = [x.attributes for x in screener if x.attributes['stock'] not in oracular_list]\n",
        "\n",
        "  stocks = [s['stock'] for s in pair_list]\n",
        "\n",
        "  return stocks\n",
        "\n",
        "def PrepareData(days, init_df):\n",
        "  df = init_df.copy()\n",
        "  df['future'] = df['close'].shift(-days)\n",
        "  last_sequence = np.array(df[['close']].tail(days))\n",
        "  df.dropna(inplace=True)\n",
        "  sequence_data = []\n",
        "  sequences = deque(maxlen=N_STEPS)\n",
        "\n",
        "  for entry, target in zip(df[['close'] + ['date']].values, df['future'].values):\n",
        "      sequences.append(entry)\n",
        "      if len(sequences) == N_STEPS:\n",
        "          sequence_data.append([np.array(sequences), target])\n",
        "\n",
        "  last_sequence = list([s[:len(['close'])] for s in sequences]) + list(last_sequence)\n",
        "  last_sequence = np.array(last_sequence).astype(np.float32)\n",
        "\n",
        "  # construct the X's and Y's\n",
        "  X, Y = [], []\n",
        "  for seq, target in sequence_data:\n",
        "      X.append(seq)\n",
        "      Y.append(target)\n",
        "\n",
        "  # convert to numpy arrays\n",
        "  X = np.array(X)\n",
        "  Y = np.array(Y)\n",
        "\n",
        "  return df, last_sequence, X, Y\n",
        "\n",
        "def GetTrainedModel(x_train, y_train):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(60, return_sequences=True, input_shape=(N_STEPS, len(['close']))))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(LSTM(120, return_sequences=False))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(20))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  BATCH_SIZE = 8\n",
        "  EPOCHS = 80\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "  model.fit(x_train, y_train,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=EPOCHS,\n",
        "            verbose=1)\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def shark_oracular_go(request):\n",
        "  stocks = GetStocks()\n",
        "  if len(stocks) > 0:\n",
        "    # Current date\n",
        "    date_now = tm.strftime('%Y-%m-%d')\n",
        "    date_2_years_back = (dt.date.today() - dt.timedelta(days=736)).strftime('%Y-%m-%d')\n",
        "\n",
        "    # LOAD DATA\n",
        "    init_df = yf.get_data(stocks[0], start_date=date_2_years_back, end_date=date_now, interval='1d')\n",
        "    init_df = init_df.drop(['open', 'high', 'low', 'adjclose', 'ticker', 'volume'], axis=1)\n",
        "    init_df['date'] = init_df.index\n",
        "\n",
        "    # Scale data for ML engine\n",
        "    scaler = MinMaxScaler()\n",
        "    init_df['close'] = scaler.fit_transform(np.expand_dims(init_df['close'].values, axis=1))\n",
        "\n",
        "    # GET PREDICTIONS\n",
        "    predictions = []\n",
        "    for step in LOOKUP_STEPS:\n",
        "      df, last_sequence, x_train, y_train = PrepareData(step, init_df)\n",
        "      x_train = x_train[:, :, :len(['close'])].astype(np.float32)\n",
        "      model = GetTrainedModel(x_train, y_train)\n",
        "      last_sequence = last_sequence[-N_STEPS:]\n",
        "      last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "      prediction = model.predict(last_sequence)\n",
        "      predicted_price = scaler.inverse_transform(prediction)[0][0]\n",
        "      predictions.append(round(float(predicted_price), 2))\n",
        "\n",
        "    # PUBLISH PREDICTIONS\n",
        "    if len(predictions) == len(LOOKUP_STEPS):\n",
        "      PublishPredictions(stocks[0], predictions[0], predictions[1], predictions[2])\n",
        "      predictions_list = [str(d)+'$' for d in predictions]\n",
        "      predictions_str = ', '.join(predictions_list)\n",
        "      message = f'{ORACULAR_ID}: *{stocks[0]}* prediction for upcoming 3 days ({predictions_str})'\n",
        "\n",
        "      send_message(message)\n",
        "\n",
        "  return f'{ORACULAR_ID}: execution DONE!\\n'"
      ],
      "metadata": {
        "id": "xryIEykQ0-pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shark_oracular_go({})"
      ],
      "metadata": {
        "id": "tkS25gx0026H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}